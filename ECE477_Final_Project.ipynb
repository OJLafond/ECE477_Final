{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB8LiXI8cLW8"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUELwexBb9MT"
      },
      "outputs": [],
      "source": [
        "!pip install wfdb\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wfdb\n",
        "from scipy.signal import resample\n",
        "from scipy.signal import decimate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM1bFZIEb9ns"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rTiUQB0NIY-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsxh49PlcUOS"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWetmezmb8px"
      },
      "outputs": [],
      "source": [
        "!wget -r -N -c -np https://physionet.org/files/noneeg/1.0.0/ -P /content/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYxN4fupcd1P"
      },
      "source": [
        "Define the data directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fc_KF1Ocehl"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/data/physionet.org/files/noneeg/1.0.0/\"\n",
        "num_subjects = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_wAk9rhc2Do"
      },
      "source": [
        "Function to extract information from the header file of each subject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8asBIvxWc6Kx"
      },
      "outputs": [],
      "source": [
        "def parse_header_file(header_path):\n",
        "\n",
        "    metadata = {}\n",
        "\n",
        "    with open(header_path, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line.startswith(\"#\"):\n",
        "                key_value = line[2:].split(\": \")\n",
        "                if len(key_value) == 2:\n",
        "                    key, value = key_value\n",
        "                    metadata[key] = value\n",
        "            # Extract the number of samples and sampling frequency from the first line\n",
        "            elif len(line.split()) == 4 and line.split()[1].isdigit():\n",
        "                parts = line.split()\n",
        "                metadata[\"Number of Samples\"] = int(parts[3])\n",
        "                metadata[\"Sampling Frequency\"] = float(parts[2])\n",
        "\n",
        "            else:\n",
        "                parts = line.split()\n",
        "                if len(parts) > 8 and \".dat\" in parts[0]:\n",
        "                    signal_name = parts[-1]\n",
        "\n",
        "\n",
        "    return metadata\n",
        "\n",
        "\n",
        "parse_header_file(os.path.join(DATA_DIR, f\"Subject1_AccTempEDA.hea\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwoXNhuslQik"
      },
      "source": [
        "Function to load the signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgjUDudA7UX4"
      },
      "outputs": [],
      "source": [
        "# Example subject\n",
        "subject_id = 1\n",
        "record_path = os.path.join(DATA_DIR, f\"Subject{subject_id}_AccTempEDA\")\n",
        "\n",
        "# Read the annotations for the subject\n",
        "annotation_path = os.path.join(DATA_DIR, f\"Subject{subject_id}_AccTempEDA\")\n",
        "annotations = wfdb.rdann(annotation_path, 'atr')\n",
        "\n",
        "# Print the annotations to see the available attributes\n",
        "print(annotations.__dict__)  # Print all available attributes of the annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsG5R_sGTgz1"
      },
      "source": [
        "Create a dataframe containing the information of a sebject in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfL3IkUulTLR"
      },
      "outputs": [],
      "source": [
        "def load_signal(subject_id):\n",
        "  record_pathEDA = os.path.join(DATA_DIR, f\"Subject{subject_id}_AccTempEDA\")\n",
        "  record_pathSpO2HR = os.path.join(DATA_DIR, f\"Subject{subject_id}_SpO2HR\")\n",
        "\n",
        "  # Extract the metadata and scaling factors\n",
        "  metadataEDA = parse_header_file(record_pathEDA + \".hea\")\n",
        "  metadataSpO2HR = parse_header_file(record_pathSpO2HR + \".hea\")\n",
        "\n",
        "  # Read signal data\n",
        "  signalsEDA, fieldsEDA = wfdb.rdsamp(record_pathEDA)\n",
        "  signalsSpO2HR, fieldsSpO2HR = wfdb.rdsamp(record_pathSpO2HR)\n",
        "\n",
        "  # Convert the signals to a dataframe\n",
        "  df1 = pd.DataFrame(signalsEDA, columns=['ax', 'ay', 'az', 'temp', 'EDA'])\n",
        "  df2 = pd.DataFrame(signalsSpO2HR, columns=['SpO2', 'HR'])\n",
        "\n",
        "  # Read the annotations (task stages)\n",
        "  annotation_pathEDA = os.path.join(DATA_DIR, f\"Subject{subject_id}_AccTempEDA\")\n",
        "  annotationsEDA = wfdb.rdann(annotation_path, 'atr')\n",
        "\n",
        "  # Determine sampling rates from metadata\n",
        "  fs_eda = int(metadataEDA['Number of Samples'])  # AccTempEDA frequency\n",
        "  fs_spo2 = int(metadataSpO2HR['Number of Samples'])  # SpO2HR frequency\n",
        "\n",
        "  # Compute downsampling factor\n",
        "  downsample_factor = fs_eda // fs_spo2  # Assuming fs_eda is a multiple of fs_spo2\n",
        "\n",
        "  # Repeat each SpO2 and HR value by the downsampling factor\n",
        "  df2_repeated = df2.loc[df2.index.repeat(downsample_factor)].reset_index(drop=True)\n",
        "\n",
        "  # Ensure the repeated df2 matches the length of df1\n",
        "  min_len = min(len(df1), len(df2_repeated))\n",
        "  df1 = df1.iloc[:min_len].reset_index(drop=True)\n",
        "  df2_repeated = df2_repeated.iloc[:min_len].reset_index(drop=True)\n",
        "\n",
        "  # Combine signals\n",
        "  df = pd.concat([df1, df2_repeated], axis=1)\n",
        "\n",
        "  metadata = {**metadataEDA, **metadataSpO2HR}\n",
        "\n",
        "  # Initialize the list to store task stages\n",
        "  task_stages = [''] * len(df)\n",
        "\n",
        "  # Loop through the annotations and assign task stages\n",
        "  for i in range(len(annotations.sample) - 1):  # Loop through each annotation\n",
        "      start_idx = annotations.sample[i]-1\n",
        "      end_idx = annotations.sample[i + 1]\n",
        "      task_stage = annotations.aux_note[i]\n",
        "\n",
        "      # Assign the task stage to all samples between start_idx and end_idx\n",
        "      task_stages[start_idx:end_idx] = [task_stage] * (end_idx - start_idx)\n",
        "\n",
        "  # For the last annotation, assign the task stage to the remaining samples\n",
        "  if len(annotations.sample) > 0:\n",
        "      start_idx = annotations.sample[-1]\n",
        "      task_stage = annotations.aux_note[-1]\n",
        "      task_stages[start_idx:] = [task_stage] * (len(df) - start_idx)\n",
        "\n",
        "  df['task'] = task_stages\n",
        "\n",
        "\n",
        "\n",
        "  return df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqvsp9IrT09Q"
      },
      "source": [
        "Combine the data from all subjects into one large dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x00S2JAvwqj_"
      },
      "outputs": [],
      "source": [
        "all_subjects = []\n",
        "for subject_id in range(1, num_subjects + 1):\n",
        "    df = load_signal(subject_id)\n",
        "    df[\"subject_id\"] = subject_id\n",
        "    all_subjects.append(df)\n",
        "\n",
        "# Merge into one DataFrame\n",
        "final_df = pd.concat(all_subjects, ignore_index=True)\n",
        "\n",
        "final_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GojzWSOApy6d"
      },
      "source": [
        "Not necessary, but may be useful if examining the finer differences between the stressed and relaxed states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqdoAR3LlZqX"
      },
      "outputs": [],
      "source": [
        "def label_relaxation_stage(df):\n",
        "    current_subject = None\n",
        "    relaxation_counter = 0  # Start at 0 so first increment makes it Relaxation1\n",
        "    last_task = None\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Detect subject change\n",
        "        if row['subject_id'] != current_subject:\n",
        "            current_subject = row['subject_id']\n",
        "            relaxation_counter = 0  # Reset counter for new subject\n",
        "            last_task = None  # Reset last task tracking\n",
        "\n",
        "        if row['task'] == 'Relax':\n",
        "            if last_task != 'Relax':\n",
        "                relaxation_counter += 1  # Only increment when entering a new Relaxation phase\n",
        "            df.at[index, 'task'] = f\"Relax{relaxation_counter}\"\n",
        "\n",
        "        last_task = row['task']  # Track previous task\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply this function to your final dataframe\n",
        "final_df = label_relaxation_stage(final_df)\n",
        "\n",
        "final_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1imkIc1UG0I"
      },
      "source": [
        "Turn this into a binary classification problem with two labels (stress, relax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpu14ZSayjAo"
      },
      "outputs": [],
      "source": [
        "def combine_stress_relax_labels(df):\n",
        "    # Define a mapping of task stages to the new \"Stress\" and \"Relax\" categories\n",
        "    # Adjust this dictionary based on your specific task labels\n",
        "    stress_labels = ['CognitiveStress', 'EmotionalStress', 'PhysicalStress']  # Stress categories\n",
        "    relax_labels = ['Relax1', 'Relax2', 'Relax3', 'Relax4']  # Relax categories\n",
        "\n",
        "    # Create a new column 'task_combined' where we combine the labels into 'Stress' and 'Relax'\n",
        "    df['task_combined'] = df['task'].apply(lambda x: 'Stress' if x in stress_labels else ('Relax' if x in relax_labels else 'Unknown'))\n",
        "\n",
        "    return df\n",
        "\n",
        "final_df = combine_stress_relax_labels(final_df)\n",
        "final_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vaqcm-3svV8n"
      },
      "source": [
        "Check if there are any missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9kezN1RtIan"
      },
      "outputs": [],
      "source": [
        "print(final_df['task'].isna().sum())  # Check if there are NaN values\n",
        "print(final_df[final_df['task'] == \"\"])  # Check if any tasks are empty strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgFxME6fU3Aa"
      },
      "source": [
        "Apply min-max normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmTOfaJfU2OZ"
      },
      "outputs": [],
      "source": [
        "columns_to_normalize = ['ax', 'ay', 'az', 'temp', 'EDA', 'SpO2', 'HR']\n",
        "\n",
        "final_df[columns_to_normalize] = (final_df[columns_to_normalize] - final_df[columns_to_normalize].min()) / (final_df[columns_to_normalize].max() - final_df[columns_to_normalize].min())\n",
        "\n",
        "final_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj_cKJ7I_htC"
      },
      "source": [
        "Do a non-overlapping windowed average to reduce noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XxH-j1hYYZX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Columns to average\n",
        "signal_cols = ['ax', 'ay', 'az', 'temp', 'EDA', 'SpO2', 'HR']\n",
        "id_cols = ['subject_id', 'task_combined']\n",
        "window_size = 10  # Change this to adjust how much you reduce the dataset\n",
        "\n",
        "# Sort to preserve time order\n",
        "final_df_sorted = final_df.sort_values(id_cols)\n",
        "\n",
        "# Function to apply chunked averaging within each group\n",
        "def downsample_group(group):\n",
        "    # Truncate group to multiple of window_size\n",
        "    n = len(group) // window_size * window_size\n",
        "    group = group.iloc[:n]\n",
        "\n",
        "    # Reshape and average\n",
        "    averaged = group[signal_cols].values.reshape(-1, window_size, len(signal_cols)).mean(axis=1)\n",
        "\n",
        "    # Repeat metadata for each new chunk\n",
        "    meta = group[id_cols].iloc[::window_size].reset_index(drop=True)\n",
        "\n",
        "    return pd.concat([meta.reset_index(drop=True),\n",
        "                      pd.DataFrame(averaged, columns=signal_cols)], axis=1)\n",
        "\n",
        "# Apply to each subject/task group\n",
        "downsampled_df = final_df_sorted.groupby(id_cols, group_keys=False).apply(downsample_group).reset_index(drop=True)\n",
        "\n",
        "downsampled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd08aGB0wH-n"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grb5CZsnVYp2"
      },
      "source": [
        "Split the data into training and test sets and fit using a standard scaler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVw95Dj6g8FG"
      },
      "source": [
        "In the experiment they found age, height, and weight not to be useful so I haven't included these features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szcAqHgCyMUL"
      },
      "outputs": [],
      "source": [
        "#feature_columns = ['ax', 'ay', 'az', 'temp', 'EDA', 'age', 'height/cm', 'weight/kg']\n",
        "feature_columns = ['ax', 'ay', 'az', 'temp', 'EDA', 'SpO2']\n",
        "\n",
        "X = downsampled_df[feature_columns]\n",
        "y = downsampled_df['task_combined']\n",
        "\n",
        "\n",
        "# Split the data into training, validation, and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize data features using StandardScaler;\n",
        "scaler = StandardScaler()\n",
        "features_train_scaled = scaler.fit_transform(X_train)\n",
        "features_test_scaled = scaler.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mztKxUZr0EKA"
      },
      "source": [
        "### Feature Extraction (checking what features can be removed) ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9nPodW30IAX"
      },
      "outputs": [],
      "source": [
        "# Apply PCA with the maximum number of components (all features)\n",
        "pca = PCA()\n",
        "pca.fit(features_train_scaled)\n",
        "\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "cumulative_variance = explained_variance_ratio.cumsum()\n",
        "\n",
        "\n",
        "# Plot the cumulative explained variance to visualize the optimal number of components\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, len(explained_variance_ratio) + 1), cumulative_variance, marker='o', linestyle='--')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Explained Variance vs Number of Components')\n",
        "plt.axhline(y=0.95, color='r', linestyle='--')  # 95% variance line\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Find the number of components that explain at least 95% of the variance\n",
        "optimal_components = (cumulative_variance >= 0.90).argmax() + 1\n",
        "\n",
        "print(f\"Optimal number of PCA components: {optimal_components}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc9P5WzwDUlR"
      },
      "source": [
        "The optimal number of components is found to be 6 so I'm going to keep all features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mAaKaTG8CiF"
      },
      "source": [
        "Apply PCA with the optimal number of components and compare to Random Projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeyS-xri6s2B"
      },
      "outputs": [],
      "source": [
        "# Apply PCA with the optimal number of components over the train set\n",
        "pca = PCA(n_components=optimal_components)\n",
        "features_train_pca = pca.fit_transform(features_train_scaled)\n",
        "features_test_pca = pca.transform(features_test_scaled)\n",
        "\n",
        "# transform using Random Projection\n",
        "rp = GaussianRandomProjection(n_components=optimal_components, random_state=42)\n",
        "features_train_rp = rp.fit_transform(features_train_scaled)\n",
        "features_test_rp = rp.transform(features_test_scaled)\n",
        "\n",
        "\n",
        "# Compare memory efficiency (in KB)\n",
        "pca_components = pca.components_\n",
        "pca_mean = pca.mean_\n",
        "pca_memory_kb = (pca_components.nbytes + pca_mean.nbytes) / 1024\n",
        "\n",
        "rp_components = rp.components_\n",
        "rp_memory_kb = rp_components.nbytes / 1024\n",
        "\n",
        "print(f\"PCA memory usage: {pca_memory_kb:.2f} KB\")\n",
        "print(f\"Random Projection memory usage: {rp_memory_kb:.2f} KB\")\n",
        "print(f\"Memory reduction from PCA to RP: {100 * (1 - rp_memory_kb / pca_memory_kb):.2f}%\")\n",
        "\n",
        "def evaluate(X_tr, X_te, y_tr, y_te, label):\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    clf.fit(X_tr, y_tr)\n",
        "    preds = clf.predict(X_te)\n",
        "    acc = accuracy_score(y_te, preds)\n",
        "    f1 = f1_score(y_te, preds, average='weighted')\n",
        "    print(f\"{label} — Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
        "    return acc, X_tr, X_te\n",
        "\n",
        "print(\"\\nComparing PCA and Random Projection:\")\n",
        "acc_pca, X_train_pca_final, X_test_pca_final = evaluate(features_train_pca, features_test_pca, y_train, y_test, \"PCA\")\n",
        "acc_rp, X_train_rp_final, X_test_rp_final = evaluate(features_train_rp, features_test_rp, y_train, y_test, \"Random Projection\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddxL69czfJWQ"
      },
      "source": [
        "Random Projection and PCA comparison:\n",
        "\n",
        "PCA has a marginally better accuracy but the difference is not too significant. Would save a lot of space using Random Projection so this is what will be used going forward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NJgytuDfIrz"
      },
      "outputs": [],
      "source": [
        "X_train = X_train_rp_final\n",
        "X_test = X_test_rp_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3eumx1Re7BU"
      },
      "outputs": [],
      "source": [
        "# Combine the selected features and labels into DataFrames\n",
        "df_train_final = pd.DataFrame(data=X_train)\n",
        "df_train_final['task'] = y_train.reset_index(drop=True)\n",
        "\n",
        "df_test_final = pd.DataFrame(data=X_test)\n",
        "df_test_final['task'] = y_test.reset_index(drop=True)\n",
        "\n",
        "# Display the dimensionality-reduced training set\n",
        "print(\"\\nFinal Transformed Training Set:\")\n",
        "print(df_train_final)\n",
        "\n",
        "# Display the dimensionality-reduced test set\n",
        "print(\"\\nFinal Transformed Test Set:\")\n",
        "print(df_test_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JvbtQuuvcEO"
      },
      "source": [
        "### Synthetic Data Generation ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH0w8MGbGBYc"
      },
      "source": [
        "\n",
        "\n",
        "*   Implement Kernel Density Estimation (KDE) and Gaussian Mixture Models (GMM) for synthetic data generation\n",
        "\n",
        "* Label synthetic data with Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_DYIEtHvfX4"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.mixture import GaussianMixture as GMM\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwlxSStDFEMP"
      },
      "outputs": [],
      "source": [
        "random_state = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AOtUqF02cXg"
      },
      "source": [
        "Take the test and training data from the reduced dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79TbIEci2gzQ"
      },
      "outputs": [],
      "source": [
        "# Prepare X_train, y_train, X_test, y_test from final reduced-dimension DataFrames\n",
        "X_train = df_train_final.iloc[:, :-1]\n",
        "y_train = df_train_final.iloc[:, -1]\n",
        "X_test = df_test_final.iloc[:, :-1]\n",
        "y_test = df_test_final.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4fQIPiDvfur"
      },
      "source": [
        "Implement Kernel Density Estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xtgj5aaHM4X"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KernelDensity\n",
        "\n",
        "def KDE_sample_generation (X_train, X_validation):\n",
        "\n",
        "  # search over different bandwidth, find the best one\n",
        "  bw_list = [0.5, 0.7, 1, 1.5, 2, 3]\n",
        "\n",
        "  log_like = np.zeros((len(bw_list)))\n",
        "  for i, bw in enumerate(bw_list):\n",
        "    print(f\"bw = {bw}\")\n",
        "\n",
        "    kernel_density = KernelDensity(kernel='gaussian', bandwidth=bw)\n",
        "    kernel_density.fit(X_train)\n",
        "    log_like[i] = kernel_density.score(X_validation)\n",
        "\n",
        "\n",
        "  bbw = bw_list[np.argmax(log_like)]\n",
        "  print (f\"Best Bandwidth: {bbw}\")\n",
        "\n",
        "  # create model with Best Bandwidth, fit\n",
        "  kernel_density = KernelDensity(kernel='gaussian', bandwidth=bbw)\n",
        "  kernel_density.fit(X_train)\n",
        "\n",
        "  # sample 200000 samples from the model\n",
        "  X_syn = kernel_density.sample(n_samples=200000, random_state=random_state)\n",
        "  print(f\"X_syn.shape: {X_syn.shape}\")\n",
        "\n",
        "  num_features = X_syn.shape[1]  # Get the number of features from X_syn's shape\n",
        "\n",
        "\n",
        "  return X_syn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kQevhNvnbVy"
      },
      "source": [
        "Implement Gaussian Mixture Model (GMM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzODwr2znc-k"
      },
      "outputs": [],
      "source": [
        "# Generating synthetic data based on GMM model - The number of Gaussians is selected based on maximizing\n",
        "# the sum of the log-probabilities of instances in the validation set\n",
        "def GMM_sample_generation(X_train, X_validation):\n",
        "    max_components = 5\n",
        "    n_components = np.arange(1, max_components, 1)\n",
        "    sum_array = np.zeros((max_components - 1))\n",
        "    for i in n_components:\n",
        "\n",
        "        model = GMM(n_components=i, covariance_type='full', random_state=random_state)\n",
        "        model.fit(X_train)\n",
        "\n",
        "        log_likelihoods = model.score_samples(X_validation)\n",
        "        sum_array[i - 1] = sum(log_likelihoods)\n",
        "        print(f\"Accumulated log likelihood for {i} components:\", sum_array[i - 1])\n",
        "\n",
        "    n_components = np.argmax(sum_array)\n",
        "    n_components = n_components + 1\n",
        "    print(\"Number of components: {}\".format(n_components))\n",
        "\n",
        "    # define and fit the model with best number of components\n",
        "    gmm = GMM(n_components=n_components, covariance_type='full', random_state=random_state)\n",
        "    gmm.fit(X_train)\n",
        "\n",
        "    print(gmm.converged_)\n",
        "\n",
        "    out = gmm.score(X_validation)\n",
        "    print(out)\n",
        "\n",
        "    X_syn = gmm.sample(200000)\n",
        "    print(X_syn[0].shape)\n",
        "    return X_syn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBuwrXEkoPxW"
      },
      "outputs": [],
      "source": [
        "def sample_generation (X_train, X_validation, method):\n",
        "    \"\"\"supported methods: GMM, KDE\"\"\"\n",
        "    count = 100000\n",
        "    if method == \"GMM\":\n",
        "        X_syn_out = GMM_sample_generation(X_train, X_validation)\n",
        "        X_syn = X_syn_out[0]\n",
        "    elif method == \"KDE\":\n",
        "        X_syn = KDE_sample_generation(X_train, X_validation)\n",
        "    else:\n",
        "        print (\"method not supported\")\n",
        "    return X_syn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFh5ZAsgHcwy"
      },
      "source": [
        "Generate the synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3lMEbfDHhJw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming these are your PCA-transformed datasets\n",
        "print(X_train.shape)\n",
        "X_real = X_train\n",
        "X_kde = sample_generation(X_real, X_test, method='KDE')\n",
        "X_gmm = sample_generation(X_real, X_test, method='GMM')\n",
        "\n",
        "X_real = X_real.values\n",
        "\n",
        "# Plot first two PCA components directly\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(X_real[:, 0], X_real[:, 1], alpha=0.3, s=10)\n",
        "plt.title(\"Original Data\")\n",
        "plt.xlabel(\"Projected Feature 1\")\n",
        "plt.ylabel(\"Projected Feature 2\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(X_kde[:, 0], X_kde[:, 1], alpha=0.3, s=10, color='green')\n",
        "plt.title(\"Synthetic Data (KDE)\")\n",
        "plt.xlabel(\"Projected Feature 1\")\n",
        "plt.ylabel(\"Projected Feature 2\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(X_gmm[:, 0], X_gmm[:, 1], alpha=0.3, s=10, color='orange')\n",
        "plt.title(\"Synthetic Data (GMM)\")\n",
        "plt.xlabel(\"Projected Feature 1\")\n",
        "plt.ylabel(\"Projected Feature 2\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A17IKz408wGo"
      },
      "source": [
        "Evaluate the similarity of synthetic data to the original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKgV5CLi9hcf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "def compute_mmd_rbf(X, Y, gamma=1.0):\n",
        "    \"\"\"Compute the MMD between two datasets using an RBF kernel.\"\"\"\n",
        "    XX = cdist(X, X, 'sqeuclidean')\n",
        "    YY = cdist(Y, Y, 'sqeuclidean')\n",
        "    XY = cdist(X, Y, 'sqeuclidean')\n",
        "\n",
        "    K_XX = np.exp(-gamma * XX)\n",
        "    K_YY = np.exp(-gamma * YY)\n",
        "    K_XY = np.exp(-gamma * XY)\n",
        "\n",
        "    m = X.shape[0]  # assume X and Y have the same size\n",
        "\n",
        "    mmd = (K_XX.sum() - np.trace(K_XX)) / (m * (m - 1)) \\\n",
        "        + (K_YY.sum() - np.trace(K_YY)) / (m * (m - 1)) \\\n",
        "        - 2 * K_XY.mean()\n",
        "\n",
        "    return mmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF82Uv6i8vr1"
      },
      "outputs": [],
      "source": [
        "# evaluate on a random subset rather than the entire dataset so that it's less data intensive\n",
        "eval_n = 3000  # or 5000, depending on what fits in memory\n",
        "\n",
        "idx = np.random.choice(X_real.shape[0], eval_n, replace=False)\n",
        "X_real_eval = X_real[idx]\n",
        "X_kde_eval = X_kde[idx]\n",
        "X_gmm_eval = X_gmm[idx]\n",
        "\n",
        "mmd_kde = compute_mmd_rbf(X_real_eval, X_kde_eval, gamma=0.5)\n",
        "mmd_gmm = compute_mmd_rbf(X_real_eval, X_gmm_eval, gamma=0.5)\n",
        "\n",
        "print(\"MMD (KDE):\", mmd_kde)\n",
        "print(\"MMD (GMM):\", mmd_gmm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0Pb4ISzDe53"
      },
      "source": [
        "The best synthetic is generated using the KDE model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNCyenyHDvMf"
      },
      "outputs": [],
      "source": [
        "X_syn = X_kde\n",
        "print(X_syn.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl8d_asFGn5x"
      },
      "source": [
        "Train a decision tree on the training data, which will then be used to label the synthetic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1x1khmqsLVNI"
      },
      "outputs": [],
      "source": [
        "# Using the Random forest model to label the synthetic data\n",
        "validation_accs = []\n",
        "train_accs = []\n",
        "\n",
        "# go over different max_depth of Random forest\n",
        "for i in range (1, 30):\n",
        "  print(f\"training Random forest max_depth={i}\")\n",
        "  clf = RandomForestClassifier(n_estimators=500, max_depth=i, criterion='entropy', random_state=random_state)\n",
        "\n",
        "  # fit the model, and save training accuracy in train_accs, validation accuracy in validation_accs\n",
        "  clf.fit(X_train, y_train)\n",
        "  train_accs.append(clf.score(X_train, y_train))\n",
        "  validation_accs.append(clf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJcDteoPLw1M"
      },
      "outputs": [],
      "source": [
        "plt.title('Training and validation accuracy vs. Tree depth')\n",
        "plt.plot(train_accs, label='Training accuracy')\n",
        "plt.plot(validation_accs, label='Validation accuracy')\n",
        "plt.xlabel(\"Random Forest Depth\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "best_tree_id = validation_accs.index(max(validation_accs))\n",
        "best_tree_depth = best_tree_id + 1\n",
        "print(f\"Baseline Random Forest depth={best_tree_depth}\")\n",
        "print(f\"train acc={train_accs[best_tree_id]}\")\n",
        "print(f\"validation acc={validation_accs[best_tree_id]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTEekzAIrZ60"
      },
      "source": [
        "Label the synthetic data using the decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf-updeorcc1"
      },
      "outputs": [],
      "source": [
        "# after finding the best depth, we will retrain a random forset with both training and validation data\n",
        "\n",
        "X_train_total = np.concatenate((X_train, X_test), axis=0)\n",
        "y_train_total = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=350, max_depth=best_tree_depth, criterion='gini', random_state=random_state)\n",
        "# fit the model with total data, and report training accuracy\n",
        "clf.fit(X_train_total, y_train_total)\n",
        "train_acc = clf.score(X_train_total, y_train_total)\n",
        "print(f\"train acc={train_acc}\")\n",
        "\n",
        "# label the synthetic data with current model\n",
        "y_syn = clf.predict(X_syn)\n",
        "print(f\"y_syn.shape: {y_syn.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BrQDQbXbVvl"
      },
      "source": [
        "Combine data with the synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QbVu1gIbiRV"
      },
      "outputs": [],
      "source": [
        "# Use synthetic data to pretrain the model\n",
        "X_train = X_syn\n",
        "y_train = y_syn\n",
        "\n",
        "# Done with synthetic data — now safe to clear it\n",
        "del X_syn, y_syn\n",
        "import gc\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRLeUS3yFHzS"
      },
      "source": [
        "##Find the optimal architecture using SCANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOMacey3Vgor"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "RANDOM_STATE = 0\n",
        "np.random.seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EdoRzzYVpM_"
      },
      "outputs": [],
      "source": [
        "# define some util functions\n",
        "\n",
        "def neuronMask(mask, add_index, func='in', sparse=False, ratio=0.2):\n",
        "    if sparse:\n",
        "        num = int(mask.size(0)*ratio)\n",
        "        if func == 'in':\n",
        "            for i in add_index:\n",
        "                indices = list(range(mask.size(0)))\n",
        "                np.random.shuffle(indices)\n",
        "                for j in indices[:num]:\n",
        "                    mask[j, i] = 1\n",
        "        elif func == 'out':\n",
        "            for i in add_index:\n",
        "                indices = list(range(mask.size(1)))\n",
        "                np.random.shuffle(indices)\n",
        "                for j in indices[:num]:\n",
        "                    mask[i, j] = 1\n",
        "    else:\n",
        "        if func == 'in':\n",
        "            for i in add_index:\n",
        "\t            mask[:, i] = 1\n",
        "        elif func == 'out':\n",
        "            for i in add_index:\n",
        "                mask[i, :] = 1\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyUZq9oVVwd-"
      },
      "source": [
        "Define the deep neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWU4ANZ4Vy20"
      },
      "outputs": [],
      "source": [
        "class SDNN(object):\n",
        "    def __init__(self, in_num, out_num, init_size, max_size, batch_size, scheme= 'A', **kwargs):\n",
        "        self.in_num = in_num # The number of input features\n",
        "        self.out_num = out_num # The number of output classes\n",
        "        self.init_size = init_size # the inital number of hidden neurons\n",
        "        self.max_size = max_size  # max number of allowed hidden neurons in the architecture\n",
        "        self.cur_size = init_size - 1  # current size of hidden neurons\n",
        "        self.batch_size = batch_size # Batch size\n",
        "        self.name = 'SDNN' # name of the model\n",
        "        self.flag = 0\n",
        "\n",
        "        self.epoch = 0\n",
        "        self.best_acc = 0\n",
        "        self.best_acc_prune = 0\n",
        "        self.now_acc = 0\n",
        "        self.connection_count = 0\n",
        "\n",
        "        self.scheme = scheme\n",
        "\n",
        "\n",
        "    # Forward pass\n",
        "    # we first compute the hidden activations by utilizing the input to hidden weights (w1) , and hidden to hidden weights,\n",
        "    # (w2) and their corresponding mask matrices (m1, m2), as well as the hidden biases (b1)\n",
        "    # After computing the hidden activations, we use it alongside hidden to out weight matrix (w3) and corresponding\n",
        "    # mask (m3), and input to output connections (w4) and its corresponding mask (m4), and output biases (b2)\n",
        "    # at the end we return the computed output\n",
        "    def forward(self, x, retain_grad = True):\n",
        "        self.hidden = torch.zeros(x.size(0), self.max_size)\n",
        "\n",
        "        for i,j in enumerate(self.active_index):\n",
        "            self.hidden[:, j] = F.relu((torch.mm(self.hidden.clone(), torch.mul(self.w2[:, j], self.m2[:, j]).view(-1, 1))\n",
        "                                       + torch.mm(x, torch.mul(self.w1[:, j], self.m1[:, j]).view(-1,1))\n",
        "                                       + self.b1[:, j])).squeeze(1)\n",
        "\n",
        "        out = torch.mm(self.hidden, torch.mul(self.w3, self.m3)) \\\n",
        "                  + torch.mm(x, torch.mul(self.w4, self.m4)) \\\n",
        "                  + self.b2\n",
        "\n",
        "        if retain_grad:\n",
        "            out.retain_grad()\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    # used in connection growth\n",
        "    def forwardMask(self, display=True):\n",
        "        for i,j in enumerate(self.active_index):\n",
        "            mask_idx = list(set(range(self.max_size)) - set(self.active_index[:i]))\n",
        "            self.m2.data[:, j][mask_idx] = 0\n",
        "        if display:\n",
        "            print('Forward mask, m2: %d' %np.count_nonzero(self.m2.data))\n",
        "\n",
        "\n",
        "    def backwardGrad(self, outgrad):\n",
        "        self.hidden.grad = torch.mm(outgrad, torch.t(self.w3))\n",
        "        rev_idx = np.flip(self.active_index, axis=0)\n",
        "        for i,j in enumerate(rev_idx):\n",
        "            for k in range(i):\n",
        "                self.hidden.grad.data[:, j] = self.hidden.grad.data[:, j] + self.hidden.grad.data[:, k] \\\n",
        "                                                  *self.w2.data[j, k]\n",
        "\n",
        "\n",
        "    def displayConnection(self, display=True):\n",
        "        \"\"\"it shows the number of active weights in m1, m2, m3, and m4 masks\"\"\"\n",
        "        m1 = 0\n",
        "        m2 = 0\n",
        "        m3 = 0\n",
        "        m4 = np.count_nonzero(self.m4.data)\n",
        "        for i,j in enumerate(self.active_index):\n",
        "            m1 += np.count_nonzero(self.m1.data[:, j])\n",
        "            m3 += np.count_nonzero(self.m3.data[j, :])\n",
        "            for k in range(i):\n",
        "                m2 += np.count_nonzero(self.m2.data[self.active_index[k]][j])\n",
        "\n",
        "        if display:\n",
        "            print('Connection Info: ')\n",
        "            print('m1: %d, m2: %d, m3: %d, m4: %d' %(m1,m2,m3,m4))\n",
        "            print('Total: %d' % (m1+m2+m3+m4))\n",
        "        return m1, m2, m3, m4, m1+m2+m3+m4\n",
        "\n",
        "\n",
        "    def save_checkpoint(self, state, is_best, folder_to_save, filename = '_checkpoint.pth.tar'):\n",
        "        name_to_save = os.path.join(folder_to_save, self.name + filename)\n",
        "        torch.save(state, name_to_save)\n",
        "        if is_best:\n",
        "            shutil.copyfile(name_to_save, os.path.join(folder_to_save, self.name + '_model_best.pth.tar'))\n",
        "            print(f\"also saved as the best checkpoint to {os.path.join(folder_to_save, self.name + '_model_best.pth.tar')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcSpZAskO9mN"
      },
      "source": [
        "Function to load the training data that we will use to learn the architcture and the test data used to evaluate everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWkywd6aPKIz"
      },
      "outputs": [],
      "source": [
        "def load_data_train(X, y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    X_train = X_train.astype(float)\n",
        "    X_test = X_test.astype(float)\n",
        "    y_train = np.where(y_train == 'Relax', 0, np.where(y_train == 'Stress', 1, y_train)).astype(int)\n",
        "    y_test = np.where(y_test == 'Relax', 0, np.where(y_test == 'Stress', 1, y_test)).astype(int)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87ltFPOwWG9U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def to_numpy_safe(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.detach().cpu().numpy()\n",
        "    return x\n",
        "\n",
        "def loadData(self, X_train, y_train, X_test, y_test, mode='train', fold=None):\n",
        "    if mode == 'train':\n",
        "        # Ensure inputs are NumPy arrays\n",
        "        X_train = to_numpy_safe(X_train)\n",
        "        y_train = to_numpy_safe(y_train)\n",
        "\n",
        "        self.X_train, self.y_train, self.X_validation, self.y_validation = load_data_train(X_train, y_train)\n",
        "\n",
        "        self.X_train = torch.tensor(self.X_train, dtype=torch.float32)\n",
        "        self.y_train = torch.tensor(self.y_train.reshape(-1), dtype=torch.long)\n",
        "\n",
        "        self.X_validation = torch.tensor(self.X_validation, dtype=torch.float32)\n",
        "        self.y_validation = torch.tensor(self.y_validation.reshape(-1), dtype=torch.long)\n",
        "\n",
        "        self.traindata = torch.utils.data.TensorDataset(self.X_train, self.y_train)\n",
        "        self.trainloader = torch.utils.data.DataLoader(self.traindata, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        self.validationdata = torch.utils.data.TensorDataset(self.X_validation, self.y_validation)\n",
        "        self.validationloader = torch.utils.data.DataLoader(self.validationdata, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    elif mode == 'test':\n",
        "        X_test = to_numpy_safe(X_test)\n",
        "        y_test = to_numpy_safe(y_test)\n",
        "\n",
        "        self.X_test = X_test.astype(float)\n",
        "        self.y_test = np.where(y_test == 'Relax', 0, np.where(y_test == 'Stress', 1, y_test)).astype(int)\n",
        "\n",
        "        self.X_test = torch.tensor(self.X_test, dtype=torch.float32)\n",
        "        self.y_test = torch.tensor(self.y_test.reshape(-1), dtype=torch.long)\n",
        "\n",
        "        self.testdata = torch.utils.data.TensorDataset(self.X_test, self.y_test)\n",
        "        self.testloader = torch.utils.data.DataLoader(self.testdata, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "SDNN.loadData = loadData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83O5RbzcWkjk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def structureInit(self, load=False, sparse=True, ratio=0.2, file=None):\n",
        "    # input to hidden\n",
        "    self.w1 = torch.randn(self.in_num, self.max_size) * 0.1\n",
        "    self.m1 = torch.zeros(self.in_num, self.max_size)\n",
        "    # hidden to hidden\n",
        "    self.w2 = torch.randn(self.max_size, self.max_size) * 0.1\n",
        "    self.m2 = torch.ones(self.max_size, self.max_size)\n",
        "    # hidden to output\n",
        "    self.w3 = torch.randn(self.max_size, self.out_num) * 0.1\n",
        "    self.m3 = torch.zeros(self.max_size, self.out_num)\n",
        "    # input to output\n",
        "    self.w4 = torch.randn(self.in_num, self.out_num) * 0.1\n",
        "    self.m4 = torch.ones(self.in_num, self.out_num)\n",
        "\n",
        "    self.b1 = torch.zeros(1, self.max_size)\n",
        "    self.b2 = torch.zeros(1, self.out_num)\n",
        "\n",
        "    self.w1.requires_grad = True\n",
        "    self.w2.requires_grad = True\n",
        "    self.w3.requires_grad = True\n",
        "    self.w4.requires_grad = True\n",
        "    self.b1.requires_grad = True\n",
        "    self.b2.requires_grad = True\n",
        "\n",
        "    self.params = {'w1': self.w1, 'w2': self.w2, 'w3': self.w3, 'w4': self.w4,\n",
        "                   'm1': self.m1, 'm2': self.m2, 'm3': self.m3, 'm4': self.m4,\n",
        "                  }\n",
        "\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    self.optimizer = optim.SGD([self.w1, self.w2, self.w3, self.w4, self.b1, self.b2], lr=0.001, momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
        "\n",
        "\n",
        "    if load == False:\n",
        "        self.active_index = list(range(self.init_size))\n",
        "        if sparse:\n",
        "            self.m1.data = neuronMask(self.m1.data, self.active_index, sparse=True, ratio=ratio)\n",
        "        else:\n",
        "            self.m1.data = neuronMask(self.m1.data, self.active_index)\n",
        "        self.m3.data = neuronMask(self.m3.data, self.active_index, 'out')\n",
        "        self.b1.data = neuronMask(self.b1.data, self.active_index)\n",
        "\n",
        "\n",
        "    else:\n",
        "        checkpoint = torch.load(file, weights_only=True)\n",
        "        self.active_index = checkpoint['active_index']\n",
        "        self.w1.data = checkpoint['state_dict']['w1']\n",
        "        self.m1.data = checkpoint['state_dict']['m1']\n",
        "        self.w2.data = checkpoint['state_dict']['w2']\n",
        "        self.m2.data = checkpoint['state_dict']['m2']\n",
        "        self.w3.data = checkpoint['state_dict']['w3']\n",
        "        self.m3.data = checkpoint['state_dict']['m3']\n",
        "        self.w4.data = checkpoint['state_dict']['w4']\n",
        "        self.m4.data = checkpoint['state_dict']['m4']\n",
        "        self.b1.data = checkpoint['state_dict']['b1']\n",
        "        self.b2.data = checkpoint['state_dict']['b2']\n",
        "        self.epoch = checkpoint['epoch']\n",
        "        self.best_acc = checkpoint['best_acc']\n",
        "        self.now_acc = checkpoint['now_acc']\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "\n",
        "SDNN.structureInit = structureInit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8TErszbWtib"
      },
      "outputs": [],
      "source": [
        "def train(self, duration=10, folder_to_save='tmp'):\n",
        "    for epoch in range(self.epoch, self.epoch+duration): #loop over the dataset multiple times based on #epochs\n",
        "        running_loss = 0.0\n",
        "        # reading the data using the data loaders defined earlier\n",
        "        for i, data in enumerate(self.trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            inputs.requires_grad_(True)\n",
        "            # zero the parameter gradients\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = self.forward(inputs)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # computing the running loss\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # updating the weight matrices\n",
        "            self.w1.data = self.w1.data * self.m1.data\n",
        "            self.w2.data = self.w2.data * self.m2.data\n",
        "            self.w3.data = self.w3.data * self.m3.data\n",
        "            self.w4.data = self.w4.data * self.m4.data\n",
        "\n",
        "        # computing the train accuracy\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for i, data in enumerate(self.trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            #inputs = inputs.view(inputs.size(0), -1)\n",
        "            outputs = self.forward(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels.data).sum()\n",
        "            total += labels.size(0)\n",
        "        train_acc = correct * 1. / total\n",
        "\n",
        "        # computing the validation accuracy\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for i, data in enumerate(self.validationloader, 0):\n",
        "            inputs, labels = data\n",
        "            outputs = self.forward(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels.data).sum()\n",
        "            total += labels.size(0)\n",
        "        validation_acc = correct * 1. /total\n",
        "        self.now_acc = validation_acc\n",
        "\n",
        "\n",
        "        if (validation_acc > self.best_acc_prune) and (self.flag == 1):\n",
        "            self.best_acc_prune = validation_acc\n",
        "            self.save_checkpoint({\n",
        "                'epoch': epoch,\n",
        "                'best_acc': self.best_acc,\n",
        "                'now_acc': self.now_acc,\n",
        "                'state_dict': {\n",
        "                    'w1': self.w1.data,\n",
        "                    'm1': self.m1.data,\n",
        "                    'w2': self.w2.data,\n",
        "                    'm2': self.m2.data,\n",
        "                    'w3': self.w3.data,\n",
        "                    'm3': self.m3.data,\n",
        "                    'w4': self.w4.data,\n",
        "                    'm4': self.m4.data,\n",
        "                    'b1': self.b1.data,\n",
        "                    'b2': self.b2.data,\n",
        "                },\n",
        "                'active_index': self.active_index,\n",
        "                'optimizer': self.optimizer.state_dict(),\n",
        "            }, False, folder_to_save, filename='_prune.pth.tar')\n",
        "\n",
        "        if (validation_acc > self.best_acc):\n",
        "            self.best_acc = validation_acc\n",
        "            self.save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'best_acc': self.best_acc,\n",
        "                'now_acc': self.now_acc,\n",
        "                'state_dict': {\n",
        "                    'w1': self.w1.data,\n",
        "                    'm1': self.m1.data,\n",
        "                    'w2': self.w2.data,\n",
        "                    'm2': self.m2.data,\n",
        "                    'w3': self.w3.data,\n",
        "                    'm3': self.m3.data,\n",
        "                    'w4': self.w4.data,\n",
        "                    'm4': self.m4.data,\n",
        "                    'b1': self.b1.data,\n",
        "                    'b2': self.b2.data,\n",
        "                },\n",
        "                'active_index': self.active_index,\n",
        "                'optimizer': self.optimizer.state_dict(),\n",
        "            }, True, folder_to_save)\n",
        "        else:\n",
        "            self.save_checkpoint({\n",
        "                'epoch': epoch,\n",
        "                'best_acc': self.best_acc,\n",
        "                'now_acc': self.now_acc,\n",
        "                'state_dict': {\n",
        "                    'w1': self.w1.data,\n",
        "                    'm1': self.m1.data,\n",
        "                    'w2': self.w2.data,\n",
        "                    'm2': self.m2.data,\n",
        "                    'w3': self.w3.data,\n",
        "                    'm3': self.m3.data,\n",
        "                    'w4': self.w4.data,\n",
        "                    'm4': self.m4.data,\n",
        "                    'b1': self.b1.data,\n",
        "                    'b2': self.b2.data,\n",
        "                },\n",
        "                'active_index': self.active_index,\n",
        "                'optimizer': self.optimizer.state_dict(),\n",
        "            }, False, folder_to_save)\n",
        "        print('Epoch: %d, Training accuracy: %f, Validation accuracy: %f'\n",
        "              % (epoch, train_acc, validation_acc))\n",
        "\n",
        "        m1,m2,m3,m4,m_all = self.displayConnection(display=False)\n",
        "\n",
        "    self.epoch += duration\n",
        "\n",
        "\n",
        "SDNN.train = train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1WC49TmW-s7"
      },
      "outputs": [],
      "source": [
        "# cell division function, we have the options between activation based, gradient-based, and random cell-division\n",
        "# We normally use activation-based (duplicating the cell with the highest activation value) or\n",
        "# random cell division (randomly selecting a hidden cell to be duplicated)\n",
        "# We can make this decisions either by looking at the full data, or a batch of data\n",
        "# Other than mode, the other inputs are num (shows number of neurons to be duplicated)\n",
        "# full_data that shows whether or not to use the full data for neuron selection\n",
        "# and if full data is flase, size shows how many batches to use to compute the neuron actications\n",
        "\n",
        "def cellDivision(self, mode='acti', num=1, full_data=False, size=1):\n",
        "    '''\n",
        "    Function: add neurons.\n",
        "    Arguments:\n",
        "        mode: 'acti' activation-based,'grad' gradient-based, 'rand' random\n",
        "        num: number of neurons added each time\n",
        "        full_data: whether to use full data to decide which neuron to split\n",
        "        size: if full_data=False, number of batches used to decide which neuron to split\n",
        "    '''\n",
        "\n",
        "    # computing the hidden activation values, either by using the whole data or several batches of data\n",
        "    # we sum up the hidden activations for several batches\n",
        "    if mode == 'acti':\n",
        "        activation = np.zeros(self.max_size)\n",
        "        if full_data:\n",
        "            for i, data in enumerate(self.trainloader, 0):\n",
        "                inputs,_ = data\n",
        "                self.forward(inputs)\n",
        "                activation += torch.sum(torch.abs(self.hidden.data), 0)\n",
        "        else:\n",
        "            loader = iter(self.trainloader)\n",
        "            for i in range(size):\n",
        "                inputs,_ = next(loader)\n",
        "                self.forward(inputs)\n",
        "                activation += torch.sum(torch.abs(self.hidden.data), 0).cpu().numpy()\n",
        "\n",
        "        # selecting the neurons with the highest activations to be duplicated\n",
        "        # we select 'num' neurons to be duplicated\n",
        "        max_index_arr = np.flip(np.argsort(activation)[-num:], axis=0)\n",
        "    elif mode == 'grad':\n",
        "\n",
        "        # selecting the neurons to be activated based on the hidden gradients\n",
        "        # we did not use this method in the final experiments of the paper\n",
        "        # however, it is worth exploring\n",
        "        # we use the function badwardGrad defined later to compute gradients\n",
        "        activation = np.zeros(self.max_size)\n",
        "        if full_data:\n",
        "            for i, data in enumerate(self.trainloader, 0):\n",
        "                inputs, labels = data\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.forward(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.backwardGrad(outputs)\n",
        "                activation += torch.sum(self.hidden.grad.data, 0)\n",
        "        else:\n",
        "            loader = iter(self.trainloader)\n",
        "            for i in range(size):\n",
        "                inputs, labels = loader.next()\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.forward(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "\n",
        "                self.backwardGrad(outputs)\n",
        "                activation += torch.sum(self.hidden.grad.data, 0)\n",
        "        max_index_arr = np.flip(np.argsort(activation)[-num:], axis=0)\n",
        "    elif mode == 'rand':\n",
        "        # selection 'num' neurons random from active neurons\n",
        "        max_index_arr = np.random.choice(self.active_index, size=num, replace=False)\n",
        "\n",
        "    # after selecting the neuron to be duplicated, we duplicate that neuron and its connections,\n",
        "    # and add noise to weights of the new added neuron\n",
        "\n",
        "    for max_index in max_index_arr:\n",
        "        # we add the index at the end of active_index list of active neurons\n",
        "        add_index = len(self.active_index)\n",
        "        # current size\n",
        "        self.cur_size = add_index\n",
        "        print('Max index: %d' %max_index)\n",
        "\n",
        "        # we only add a new neurons if the number of neurons will be less than the maximum number of neurons\n",
        "        # set at the beginning\n",
        "        if add_index < self.max_size:\n",
        "            print('Adding neuron: %d' %add_index)\n",
        "            python_max_index = int(max_index)  # Convert to Python int\n",
        "            if python_max_index in self.active_index:\n",
        "                self.active_index.insert(self.active_index.index(python_max_index), add_index)\n",
        "                # duplicating the masks\n",
        "                self.m1.data[:, add_index] = self.m1.data[:, python_max_index]\n",
        "                self.m2.data[:, add_index] = self.m2.data[:, python_max_index]\n",
        "                self.m3.data[add_index, :] = self.m3.data[python_max_index, :]\n",
        "\n",
        "                # duplicating the weight matrices and adding noise\n",
        "                self.w1.data[:, python_max_index] = self.w1.data[:, python_max_index]\n",
        "                self.w1.data[:, add_index] = self.w1.data[:, python_max_index] + torch.randn(self.in_num) * 0.01\n",
        "                self.w2.data[:, add_index] = self.w2.data[:, python_max_index] + torch.randn(self.max_size) * 0.01\n",
        "                self.w3.data[add_index, :] = self.w3.data[python_max_index, :] + torch.randn(self.out_num) * 0.01\n",
        "                self.b1.data[:, add_index] = self.b1.data[:, python_max_index]\n",
        "            else:\n",
        "                print(f\"Value {python_max_index} not found in active_index. Skipping insertion due to error.\")\n",
        "\n",
        "    # updating the weight matrices\n",
        "    self.w1.data = self.w1.data * self.m1.data\n",
        "    self.w2.data = self.w2.data * self.m2.data\n",
        "    self.w3.data = self.w3.data * self.m3.data\n",
        "    self.w4.data = self.w4.data * self.m4.data\n",
        "    self.displayConnection()\n",
        "\n",
        "\n",
        "SDNN.cellDivision = cellDivision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROo1kRIuXFCe"
      },
      "outputs": [],
      "source": [
        "def addConnection(self, mode='grad', percentile={'m2':90, }, size=1, full_data=False):\n",
        "    '''\n",
        "    Function: add connections.\n",
        "    Arguments:\n",
        "        mode: 'corr' correlation-based, 'grad' gradient-based, 'rand' random\n",
        "        percentile: top-k percentile of connections are added\n",
        "    '''\n",
        "    print('\\nAdding connection...')\n",
        "    self.flag = 0\n",
        "\n",
        "    cov_mat = {\n",
        "        'm1': np.zeros([self.in_num, self.max_size]),\n",
        "        'm2': np.zeros([self.max_size, self.max_size]),\n",
        "        'm3': np.zeros([self.max_size, self.out_num]),\n",
        "        'm4': np.zeros([self.in_num, self.out_num]),\n",
        "    }\n",
        "\n",
        "    # gradient-based growth\n",
        "    # we use the backwardGrad function to compute gradients\n",
        "    if mode == 'grad':\n",
        "        loader = iter(self.trainloader)\n",
        "        for i in range(size):\n",
        "            inputs, labels = next(loader)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.forward(inputs)\n",
        "\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            self.backwardGrad(outputs)\n",
        "\n",
        "            cov_mat_m1 = torch.mm(inputs.T, self.hidden.grad)\n",
        "            cov_mat_m2 = torch.mm(self.hidden.T, self.hidden.grad)\n",
        "            cov_mat_m3 = torch.mm(self.hidden.T, outputs.grad)\n",
        "            cov_mat_m4 = torch.mm(inputs.T, outputs.grad)\n",
        "\n",
        "            # add to covariance matrix values cov_mat_m1, cov_mat_m2, cov_mat_m3, cov_mat_m4\n",
        "            cov_mat['m1'] = np.add(cov_mat['m1'], cov_mat_m1.detach().numpy())\n",
        "            cov_mat['m2'] = np.add(cov_mat['m2'], cov_mat_m2.detach().numpy())\n",
        "            cov_mat['m3'] = np.add(cov_mat['m3'], cov_mat_m3.detach().numpy())\n",
        "            cov_mat['m4'] = np.add(cov_mat['m4'], cov_mat_m4.detach().numpy())\n",
        "\n",
        "    elif mode == 'rand':\n",
        "            cov_mat['m1'][:, :self.cur_size] = np.random.rand(self.in_num, self.cur_size)\n",
        "            cov_mat['m2'][:self.cur_size, :self.cur_size] = np.random.rand(self.cur_size, self.cur_size)\n",
        "            cov_mat['m3'][:self.cur_size, :] = np.random.rand(self.cur_size, self.out_num)\n",
        "            cov_mat['m4'] = np.random.rand(self.in_num, self.out_num)\n",
        "\n",
        "    for i in percentile:\n",
        "        if self.scheme == \"C\" and i == 'm2':\n",
        "          mask = np.zeros_like(cov_mat['m2'])\n",
        "          for j in range(self.max_size - 1):\n",
        "            mask[j, j + 1] = 1\n",
        "            cov_mat[i] *= mask\n",
        "\n",
        "        if len(np.nonzero(cov_mat[i])[0]) == 0:\n",
        "            threshold = 0\n",
        "        else:\n",
        "            threshold = np.percentile(cov_mat[i][np.nonzero(cov_mat[i])], percentile[i])\n",
        "        self.params[i].data[torch.Tensor(cov_mat[i])>threshold] = 1\n",
        "\n",
        "    self.forwardMask()\n",
        "    self.displayConnection()\n",
        "\n",
        "    # self.m1, self.m2, self.m3, self.m4 are masks for correspondings weights.\n",
        "    # they are float tensors containing 1. and 0. values\n",
        "    # update weights masking out corresponding values.\n",
        "    # Impprtant: For weights and masks tensors in calculation, call their .data() property\n",
        "    # to prevent tracking gradients on these tensors by torch autograd system\n",
        "\n",
        "\n",
        "    self.w1.data = self.w1.data * self.m1.data\n",
        "    self.w2.data = self.w2.data * self.m2.data\n",
        "    self.w3.data = self.w3.data * self.m3.data\n",
        "    self.w4.data = self.w4.data * self.m4.data\n",
        "\n",
        "\n",
        "\n",
        "SDNN.addConnection = addConnection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9hxnXIlbirM"
      },
      "outputs": [],
      "source": [
        "def pruneConnections(self, prune_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Prune connections with the smallest magnitude weights (among active connections).\n",
        "    Only considers weights where the corresponding mask == 1.\n",
        "    \"\"\"\n",
        "    print(\"\\nPruning connections...\")\n",
        "    self.flag = 1  # Indicates a pruning step occurred\n",
        "\n",
        "    for key in ['m1', 'm2', 'm3', 'm4']:\n",
        "        weight = self.params[key.replace('m', 'w')]\n",
        "        mask = self.params[key]\n",
        "\n",
        "        # Only consider currently active connections (mask == 1)\n",
        "        active_weights = torch.abs(weight.data[mask.data == 1])\n",
        "        if active_weights.numel() == 0:\n",
        "            continue\n",
        "\n",
        "        # Determine pruning threshold\n",
        "        threshold = torch.quantile(active_weights, prune_ratio)\n",
        "\n",
        "        # Prune (set mask to 0 where weight < threshold)\n",
        "        to_prune = (torch.abs(weight.data) < threshold) & (mask.data == 1)\n",
        "        mask.data[to_prune] = 0\n",
        "        weight.data *= mask.data  # Apply the new mask\n",
        "\n",
        "    self.displayConnection()\n",
        "\n",
        "SDNN.pruneConnections = pruneConnections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9JQAB6dXLOU"
      },
      "outputs": [],
      "source": [
        "def displayAcc(self):\n",
        "    \"\"\"computing and displaying the train and test accuracy\"\"\"\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, data in enumerate(self.trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        outputs = self.forward(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct += (predicted == labels.data).sum()\n",
        "        total += labels.size(0)\n",
        "    print('Train: %d/%d' %(correct, total))\n",
        "    train_acc = correct * 1. / total\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "\n",
        "    for i, data in enumerate(self.validationloader, 0):\n",
        "      inputs, labels = data\n",
        "      outputs = self.forward(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += (predicted == labels.data).sum()\n",
        "      total += labels.size(0)\n",
        "    print('Validation: %d/%d' %(correct, total))\n",
        "    validation_acc = correct * 1. / total\n",
        "\n",
        "\n",
        "\n",
        "    print('Train accuracy: %f, Test accuracy: %f'\n",
        "          % (train_acc, validation_acc))\n",
        "    return validation_acc\n",
        "\n",
        "\n",
        "SDNN.displayAcc = displayAcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2EZP0NsXSbf"
      },
      "outputs": [],
      "source": [
        "in_num = X_train.shape[1]\n",
        "out_num = len(np.unique(y))\n",
        "\n",
        "print(f\"Number of input features: {in_num}\")\n",
        "print(f\"Number of output classes: {out_num}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KP5FjFrZjAp"
      },
      "outputs": [],
      "source": [
        "# create folder to store checkpoints\n",
        "os.makedirs('record_full', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "VNb8-UTJRrsA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrM80laOZp1D"
      },
      "outputs": [],
      "source": [
        "def compute_sparsity(sdnet):\n",
        "    total = 0\n",
        "    zeros = 0\n",
        "    for param in [sdnet.w1, sdnet.w2, sdnet.w3, sdnet.w4, sdnet.b1, sdnet.b2]:\n",
        "        if param.requires_grad:\n",
        "            total += param.numel()\n",
        "            zeros += (param == 0).sum().item()\n",
        "    return 100 * zeros / total if total > 0 else 0\n",
        "\n",
        "model_stats = {}\n",
        "\n",
        "params_dict = {\n",
        "    'A': {\n",
        "        'init_size': 20,\n",
        "        'max_size': 150,\n",
        "        'sparse': True,\n",
        "        'sparse_ratio': 0.3,\n",
        "        'loop_num': 10,\n",
        "        'full_data': False,\n",
        "        'remove': True,\n",
        "    },\n",
        "    'B': {\n",
        "        'init_size': 100,\n",
        "        'max_size': 150,\n",
        "        'sparse': True,\n",
        "        'sparse_ratio': 0.9,\n",
        "        'loop_num': 10,\n",
        "        'full_data': False,\n",
        "        'remove': True,\n",
        "    },\n",
        "    'C': {\n",
        "        'init_size': 100,\n",
        "        'max_size': 150,\n",
        "        'sparse': True,\n",
        "        'sparse_ratio': 0.9,\n",
        "        'loop_num': 10,\n",
        "        'full_data': False,\n",
        "        'remove': True,\n",
        "    }\n",
        "}\n",
        "\n",
        "for SCHEME in [ \"B\", \"C\"]:\n",
        "    # # skipping this section for now\n",
        "    # break\n",
        "    print(f\"--- Starting training for Scheme {SCHEME} ---\")\n",
        "\n",
        "    # Set seeds for reproducibility\n",
        "    RANDOM_STATE = 0\n",
        "    np.random.seed(RANDOM_STATE)\n",
        "    random.seed(RANDOM_STATE)\n",
        "    torch.manual_seed(RANDOM_STATE)\n",
        "    torch.cuda.manual_seed(RANDOM_STATE)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # Load scheme-specific parameters\n",
        "    params = params_dict[SCHEME]\n",
        "\n",
        "    save_dir = f'/content/drive/MyDrive/test_record_ablation_{SCHEME.lower()}'\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    sdnet = SDNN(in_num, out_num, batch_size=256, scheme=SCHEME, **params)\n",
        "    sdnet.structureInit(load=False, sparse=params['sparse'], ratio=params['sparse_ratio'])\n",
        "    sdnet.loadData(mode='train', X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
        "    sdnet.train(10, save_dir)\n",
        "\n",
        "    for i in range(params['loop_num']):\n",
        "        sdnet.addConnection(mode='grad', percentile={'m2': 70, 'm1': 70, 'm3': 70, 'm4': 70}, full_data=False)\n",
        "        sdnet.train(10, save_dir)\n",
        "\n",
        "        if SCHEME == \"A\":\n",
        "            sdnet.cellDivision(full_data=params['full_data'])\n",
        "            sdnet.train(10, save_dir)\n",
        "\n",
        "        elif SCHEME in [\"B\", \"C\"]:\n",
        "            sdnet.pruneConnections(prune_ratio=0.2)\n",
        "            sdnet.train(10, save_dir)\n",
        "\n",
        "    # Save model weights\n",
        "    final_checkpoint_path = os.path.join(save_dir, 'SDNN_model_best.pth.tar')\n",
        "    torch.save({\n",
        "      'epoch': sdnet.epoch,\n",
        "      'best_acc': sdnet.best_acc,\n",
        "      'now_acc': sdnet.now_acc,\n",
        "      'state_dict': {\n",
        "          'w1': sdnet.w1.data,\n",
        "          'm1': sdnet.m1.data,\n",
        "          'w2': sdnet.w2.data,\n",
        "          'm2': sdnet.m2.data,\n",
        "          'w3': sdnet.w3.data,\n",
        "          'm3': sdnet.m3.data,\n",
        "          'w4': sdnet.w4.data,\n",
        "          'm4': sdnet.m4.data,\n",
        "          'b1': sdnet.b1.data,\n",
        "          'b2': sdnet.b2.data,\n",
        "      },\n",
        "      'active_index': sdnet.active_index,\n",
        "      'optimizer': sdnet.optimizer.state_dict(),\n",
        "    }, final_checkpoint_path)\n",
        "\n",
        "    # Record stats\n",
        "    model_file_size = os.path.getsize(final_checkpoint_path) / (1024 * 1024)\n",
        "    num_params = sum(p.numel() for p in [sdnet.w1, sdnet.w2, sdnet.w3, sdnet.w4, sdnet.b1, sdnet.b2] if p.requires_grad)\n",
        "    sparsity = compute_sparsity(sdnet)\n",
        "\n",
        "    print(f\"[SCANN] Training complete for Scheme {SCHEME}\")\n",
        "    print(f\"[SCANN] Final model size: {model_file_size:.2f} MB\")\n",
        "    print(f\"[SCANN] Trainable parameters: {num_params}\")\n",
        "    print(f\"[SCANN] Sparsity: {sparsity:.2f}%\")\n",
        "\n",
        "    model_stats[SCHEME] = {\n",
        "        'Model Size (MB)': model_file_size,\n",
        "        'Num Params': num_params,\n",
        "        'Sparsity (%)': sparsity\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQdlRk0-XvSg"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Replace with your actual path\n",
        "checkpoint_path = '/content/drive/MyDrive/test_record_ablation_a/SDNN_model_best.pth.tar'\n",
        "\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "# Print the top-level keys\n",
        "print(\"Top-level keys in checkpoint:\", checkpoint.keys())\n",
        "\n",
        "# If 'state_dict' is one of the keys, inspect its contents too\n",
        "if 'state_dict' in checkpoint:\n",
        "    print(\"\\nKeys in 'state_dict':\", checkpoint['state_dict'].keys())\n",
        "\n",
        "# Optionally inspect other metadata\n",
        "for key in checkpoint:\n",
        "    print(f\"\\nKey: {key}\")\n",
        "    print(type(checkpoint[key]))\n",
        "    if isinstance(checkpoint[key], dict):\n",
        "        print(\"Inner keys:\", checkpoint[key].keys())\n",
        "    elif isinstance(checkpoint[key], torch.Tensor):\n",
        "        print(\"Tensor shape:\", checkpoint[key].shape)\n",
        "    else:\n",
        "        print(\"Value:\", checkpoint[key])"
      ],
      "metadata": {
        "id": "XRRqOlsHxWS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "bJB231rFwID-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(checkpoint_path)\n",
        "print(checkpoint.keys())"
      ],
      "metadata": {
        "id": "GVVGjXsr1j4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ysffq_nzcI3Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, confusion_matrix, roc_auc_score\n",
        ")\n",
        "\n",
        "# Resplit the original data (real data)\n",
        "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "X_train_real = torch.tensor(X_train_rp_final, dtype=torch.float32)\n",
        "X_test_real = torch.tensor(X_test_rp_final, dtype=torch.float32)\n",
        "\n",
        "fine_tune_metrics = {}  # Stores metrics per scheme\n",
        "scheme_accuracies= {}\n",
        "\n",
        "for SCHEME in [\"A\", \"B\", \"C\"]:\n",
        "\n",
        "\n",
        "        # ----- Pre-fine-tuning evaluation -----\n",
        "    sdnet.loadData(mode='test', X_train=X_train_real, y_train=y_train_real,\n",
        "                  X_test=X_test_real, y_test=y_test_real)\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data in sdnet.testloader:\n",
        "            inputs, labels = data\n",
        "            outputs = sdnet.forward(inputs, retain_grad=False)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = correct / total\n",
        "    print(f\"[SCANN] Pre-Fine-Tuning Accuracy for Scheme {SCHEME}: {test_accuracy:.4f}\")\n",
        "    scheme_accuracies[SCHEME] = test_accuracy\n",
        "\n",
        "    print(f\"\\n[SCANN] Fine-tuning Scheme {SCHEME} on real data\")\n",
        "\n",
        "    params = {\n",
        "        'A': {'init_size': 20, 'max_size': 150, 'sparse': True, 'sparse_ratio': 0.3,\n",
        "              'loop_num': 25, 'full_data': False, 'remove': True},\n",
        "        'B': {'init_size': 100, 'max_size': 150, 'sparse': True, 'sparse_ratio': 0.9,\n",
        "              'loop_num': 15, 'full_data': False, 'remove': True},\n",
        "        'C': {'init_size': 100, 'max_size': 150, 'sparse': True, 'sparse_ratio': 0.9,\n",
        "              'loop_num': 15, 'full_data': False, 'remove': True}\n",
        "    }[SCHEME]\n",
        "\n",
        "    checkpoint_path = os.path.join('/content/drive/MyDrive/test_record_ablation_' + SCHEME.lower(), 'SDNN_model_best.pth.tar')\n",
        "    sdnet = SDNN(in_num, out_num, batch_size=256, scheme=SCHEME, **params)\n",
        "    sdnet.structureInit(load=True, file=checkpoint_path)\n",
        "\n",
        "    # Fine-tune\n",
        "    sdnet.loadData(mode='train', X_train=X_train_real, y_train=y_train_real,\n",
        "                   X_test=X_test_real, y_test=y_test_real)\n",
        "\n",
        "    fine_tune_epochs = 20\n",
        "    save_path = f'real_finetune_{SCHEME.lower()}'\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    sdnet.train(fine_tune_epochs, save_path)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    sdnet.loadData(mode='test', X_train=X_train_real, y_train=y_train_real,\n",
        "                   X_test=X_test_real, y_test=y_test_real)\n",
        "\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in sdnet.testloader:\n",
        "            inputs, labels = data\n",
        "            outputs = sdnet.forward(inputs, retain_grad=False)\n",
        "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
        "            preds = (probs > 0.5).long()\n",
        "\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_probs = np.array(all_probs)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Binary classification metrics\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    print(f\"\\n[{SCHEME}] Fine-Tuned Metrics:\")\n",
        "    print(f\"Accuracy     : {acc:.4f}\")\n",
        "    print(f\"Precision    : {precision:.4f}\")\n",
        "    print(f\"Recall       : {recall:.4f}\")\n",
        "    print(f\"F1 Score     : {f1:.4f}\")\n",
        "    print(f\"AUC          : {auc:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "    fine_tune_metrics[SCHEME] = {\n",
        "        'Accuracy': acc,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1': f1,\n",
        "        'AUC': auc,\n",
        "        'Confusion Matrix': conf_matrix,\n",
        "        'Labels': all_labels,  # Needed for ROC and PR curves\n",
        "        'Probs': all_probs     # Needed for ROC and PR curves\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    precision_recall_curve\n",
        ")"
      ],
      "metadata": {
        "id": "LFNKz1Px0366"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
        "\n",
        "# 1. Update model_stats with post-fine-tuning metrics\n",
        "for scheme in model_stats:\n",
        "    pre_acc = scheme_accuracies[scheme]\n",
        "    post_acc = fine_tune_metrics[scheme]['Accuracy']\n",
        "\n",
        "    pre_params = model_stats[scheme]['Num Params (Pre)']\n",
        "    post_params = model_stats[scheme]['Num Params (Post)']\n",
        "\n",
        "    model_stats[scheme]['Accuracy (Pre)'] = pre_acc\n",
        "    model_stats[scheme]['Accuracy (Post)'] = post_acc\n",
        "    model_stats[scheme]['Compactness (Pre)'] = pre_acc / pre_params\n",
        "    model_stats[scheme]['Compactness (Post)'] = post_acc / post_params\n",
        "\n",
        "# 2. Plot: Pre vs Post Fine-Tuning Accuracy\n",
        "schemes = list(model_stats.keys())\n",
        "pre_accuracies = [model_stats[s]['Accuracy (Pre)'] for s in schemes]\n",
        "post_accuracies = [model_stats[s]['Accuracy (Post)'] for s in schemes]\n",
        "\n",
        "x = np.arange(len(schemes))\n",
        "bar_width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(x - bar_width/2, pre_accuracies, width=bar_width, label='Pre Fine-Tuning', color='skyblue')\n",
        "plt.bar(x + bar_width/2, post_accuracies, width=bar_width, label='Post Fine-Tuning', color='lightgreen')\n",
        "plt.xticks(x, schemes)\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Pre vs Post Fine-Tuning Accuracy for SCANN Schemes')\n",
        "plt.legend()\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Plot: Compactness Pre vs Post\n",
        "pre_compact = [model_stats[s]['Compactness (Pre)'] for s in schemes]\n",
        "post_compact = [model_stats[s]['Compactness (Post)'] for s in schemes]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(x - bar_width/2, pre_compact, width=bar_width, label='Pre', color='mediumpurple')\n",
        "plt.bar(x + bar_width/2, post_compact, width=bar_width, label='Post', color='mediumseagreen')\n",
        "plt.xticks(x, schemes)\n",
        "plt.ylabel('Accuracy per Parameter')\n",
        "plt.title('Compactness Score (Pre vs Post Fine-Tuning)')\n",
        "plt.legend()\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Plot: Sparsity\n",
        "sparsities = [model_stats[s]['Sparsity (%)'] for s in schemes]\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.bar(schemes, sparsities, color='goldenrod')\n",
        "plt.ylabel('Sparsity (%)')\n",
        "plt.title('Sparsity of SCANN Schemes')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5. Summary Table\n",
        "df_summary = pd.DataFrame(model_stats).T[\n",
        "    ['Accuracy (Pre)', 'Accuracy (Post)', 'Num Params (Pre)','Num Params (Post)', 'Model Size (MB)',\n",
        "     'Sparsity (%)', 'Compactness (Pre)', 'Compactness (Post)']\n",
        "]\n",
        "display(df_summary.round(4))  # If in notebook\n",
        "# Or to print:\n",
        "print(df_summary.round(4).to_string())\n",
        "\n",
        "# 6. Confusion Matrix, ROC, PR Curves per scheme\n",
        "for scheme in schemes:\n",
        "    cm = fine_tune_metrics[scheme]['Confusion Matrix']\n",
        "    y_true = fine_tune_metrics[scheme]['Labels']\n",
        "    y_prob = fine_tune_metrics[scheme]['Probs']\n",
        "\n",
        "    # Confusion Matrix\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - Scheme {scheme}')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - Scheme {scheme}')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Precision-Recall\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_prob)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(rec, prec)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title(f'Precision-Recall Curve - Scheme {scheme}')\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_cP9_vY90pdG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}